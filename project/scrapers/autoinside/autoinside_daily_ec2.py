import asyncio
import re
import csv
import os
import boto3
from datetime import datetime, timedelta
from playwright.async_api import (
    async_playwright,
    Error as PlaywrightError,
    TimeoutError as PlaywrightTimeoutError,
)

# --- ì„¤ì • ---
BASE_LIST_URL = "https://auction.autoinside.co.kr/auction/auction_car_end_list.do"
DETAIL_PAGE_URL_TEMPLATE = (
    "https://auction.autoinside.co.kr/auction/auction_car_view.do?i_sEntryCd={entry_cd}"
)
MAX_RETRIES = 3
CONCURRENT_REQUESTS = 5  # ìƒì„¸ í˜ì´ì§€ ë™ì‹œ ìš”ì²­ ìˆ˜


def clean_number(text):
    """í…ìŠ¤íŠ¸ì—ì„œ ìˆ«ìë§Œ ì¶”ì¶œí•˜ì—¬ ì •ìˆ˜í˜•ìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
    return int(re.sub(r"[^0-9]", "", text)) if text else 0


async def get_car_detail(context, entry_cd):
    """ì°¨ëŸ‰ ìƒì„¸ ì •ë³´ í˜ì´ì§€ì—ì„œ ìƒì„¸ ë°ì´í„°ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    page = await context.new_page()
    try:
        await page.goto(
            DETAIL_PAGE_URL_TEMPLATE.format(entry_cd=entry_cd),
            wait_until="domcontentloaded",
            timeout=30000,
        )
        car_data = {"entry_cd": entry_cd}

        # --- ë°ì´í„° ì¶”ì¶œ (ê°œë³„ try-exceptë¡œ ì•ˆì •ì„± ê°•í™”) ---
        try:
            car_name_part1 = await page.locator(
                ".performance_info .car_nm .txt01"
            ).inner_text()
            car_name_part2 = await page.locator(
                ".performance_info .car_nm .txt02"
            ).inner_text()
            full_car_name = f"{car_name_part1} {car_name_part2}"
            parts = full_car_name.split(" ", 1)
            car_data["ë¸Œëœë“œ"] = parts[0]
            car_data["ì°¨ëŸ‰ì •ë³´"] = parts[1] if len(parts) > 1 else ""
        except Exception:
            car_data["ë¸Œëœë“œ"] = "N/A"
            car_data["ì°¨ëŸ‰ì •ë³´"] = "N/A"

        try:
            car_data["ì°¨ëŸ‰ë²ˆí˜¸"] = (
                await page.locator(
                    ".fixed_detail_bid_box .car_number"
                ).first.inner_text()
            ).strip()
        except Exception:
            car_data["ì°¨ëŸ‰ë²ˆí˜¸"] = "N/A"

        try:
            info_list = await page.locator(
                ".performance_info .info_list span"
            ).all_inner_texts()
            car_data["ì—°ì‹"] = clean_number(info_list[1])
            car_data["ì£¼í–‰ê±°ë¦¬"] = clean_number(info_list[2])
            car_data["ë³´ê´€ì„¼í„°"] = info_list[3].strip()
        except Exception:
            car_data.update({"ì—°ì‹": 0, "ì£¼í–‰ê±°ë¦¬": 0, "ë³´ê´€ì„¼í„°": "N/A"})

        try:
            announce_text = (
                await page.locator(".detail_bid_box .announce").inner_text()
            ).strip()
            match = re.search(r"(\d+)ì›” (\d+)ì¼", announce_text)
            if match:
                month, day = int(match.group(1)), int(match.group(2))
                year = (
                    datetime.now().year
                    if datetime.now().month >= month
                    else datetime.now().year - 1
                )
                car_data["ê²½ë§¤ì¢…ë£Œì¼"] = f"{year}-{month:02d}-{day:02d}"
            else:
                car_data["ê²½ë§¤ì¢…ë£Œì¼"] = "N/A"
        except Exception:
            car_data["ê²½ë§¤ì¢…ë£Œì¼"] = "N/A"

        try:
            raw_price = (await page.locator(".bidding_count").inner_text()).strip()
            clean_price = raw_price.replace("*", "0").replace(",", "")
            price_match = re.search(r"(\d+)ë§Œì›", clean_price)
            car_data["ë‚™ì°°ê°€(ë§Œì›)"] = int(price_match.group(1)) if price_match else 0
        except Exception:
            car_data["ë‚™ì°°ê°€(ë§Œì›)"] = 0

        return car_data
    finally:
        await page.close()


async def fetch_ids_from_page(page, page_num):
    """ì§€ì •ëœ í˜ì´ì§€ì—ì„œ ëª¨ë“  ì°¨ëŸ‰ ID(entry_cd)ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤."""
    list_page_url = f"{BASE_LIST_URL}?i_iNowPageNo={page_num}&sort=A.D_REG_DTM%20DESC"
    await page.goto(list_page_url, timeout=30000)
    await page.wait_for_selector(
        ".car_list_box .list li:first-child", state="attached", timeout=20000
    )
    links = await page.locator(".car_list_box .list li a.a_detail").all()
    return [
        await link.get_attribute("data-entrycd")
        for link in links
        if await link.get_attribute("data-entrycd")
    ]


async def main():
    """ë©”ì¸ í¬ë¡¤ë§ ì‹¤í–‰ í•¨ìˆ˜"""
    all_car_data = []
    browser = None
    local_file_name = None

    try:
        yesterday = datetime.now() - timedelta(days=1)
        yesterday_str_for_compare = yesterday.strftime("%Y-%m-%d")

        print(
            f"ğŸ” ì–´ì œ ë‚ ì§œ({yesterday_str_for_compare})ì˜ autoinside ê²½ë§¤ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤."
        )

        async with async_playwright() as p:
            browser = await p.chromium.launch(headless=True)
            context = await browser.new_context(
                user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
            )
            list_page = await context.new_page()

            page_num = 1
            stop_crawling = False

            while not stop_crawling:
                print(f"\n--- í˜ì´ì§€ {page_num} ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘ ---")
                success_on_page = False
                for attempt in range(MAX_RETRIES):
                    try:
                        entry_cds_on_page = await fetch_ids_from_page(
                            list_page, page_num
                        )
                        if not entry_cds_on_page:
                            print("ë” ì´ìƒ ì°¨ëŸ‰ ì •ë³´ê°€ ì—†ì–´ í¬ë¡¤ë§ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                            stop_crawling = True
                            success_on_page = True
                            break

                        print(
                            f"{len(entry_cds_on_page)}ê°œ ID ìˆ˜ì§‘ ì™„ë£Œ. ìƒì„¸ ì •ë³´ í™•ì¸ì„ ì‹œì‘í•©ë‹ˆë‹¤."
                        )

                        semaphore = asyncio.Semaphore(CONCURRENT_REQUESTS)
                        tasks = []
                        for entry_cd in entry_cds_on_page:

                            async def task_wrapper(cd):
                                async with semaphore:
                                    return await get_car_detail(context, cd)

                            tasks.append(task_wrapper(entry_cd))

                        results = await asyncio.gather(*tasks, return_exceptions=True)

                        page_has_yesterday_data = False
                        for car_data in results:
                            if isinstance(car_data, Exception) or not car_data:
                                continue

                            end_date_str = car_data.get("ê²½ë§¤ì¢…ë£Œì¼", "N/A")
                            if end_date_str == yesterday_str_for_compare:
                                all_car_data.append(car_data)
                                page_has_yesterday_data = True
                            elif (
                                end_date_str < yesterday_str_for_compare
                                and end_date_str != "N/A"
                            ):
                                print(
                                    f"ì–´ì œ ì´ì „ ë‚ ì§œ({end_date_str})ì˜ ì°¨ëŸ‰ì„ ë°œê²¬í•˜ì—¬ í¬ë¡¤ë§ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤."
                                )
                                stop_crawling = True

                        success_on_page = True
                        break  # ì„±ê³µ ì‹œ ì¬ì‹œë„ ë£¨í”„ íƒˆì¶œ

                    except (PlaywrightTimeoutError, PlaywrightError) as e:
                        print(
                            f"âš ï¸ í˜ì´ì§€ {page_num} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ. {attempt + 1}/{MAX_RETRIES}ë²ˆì§¸ ì¬ì‹œë„..."
                        )
                        if attempt < MAX_RETRIES - 1:
                            await list_page.reload()
                        else:
                            print(
                                f"âŒ í˜ì´ì§€ {page_num} ë°ì´í„° ìˆ˜ì§‘ì— ìµœì¢… ì‹¤íŒ¨í•˜ì—¬ í¬ë¡¤ë§ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤."
                            )
                            stop_crawling = True

                if stop_crawling or not success_on_page:
                    break

                page_num += 1

    except Exception as e:
        print(f"\nğŸš¨ ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

    finally:
        if browser:
            await browser.close()
            print("\nâœ”ï¸ ë¸Œë¼ìš°ì €ê°€ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

        if not all_car_data:
            print("âŒ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ì–´ íŒŒì¼ ì €ì¥ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        else:
            print("\nğŸ’¾ í˜„ì¬ê¹Œì§€ ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ ì €ì¥ ë° ì—…ë¡œë“œí•©ë‹ˆë‹¤...")
            try:
                yesterday = datetime.now() - timedelta(days=1)
                yesterday_str_for_compare = yesterday.strftime("%Y-%m-%d")
                yesterday_str_for_filename = yesterday.strftime("%Y%m%d")

                local_file_name = f"autoinside-{yesterday_str_for_filename}-raw.csv"

                fieldnames = [
                    "ê²½ë§¤ì¢…ë£Œì¼",
                    "ë³´ê´€ì„¼í„°",
                    "ë¸Œëœë“œ",
                    "ì°¨ëŸ‰ì •ë³´",
                    "ì—°ì‹",
                    "ì°¨ëŸ‰ë²ˆí˜¸",
                    "ì£¼í–‰ê±°ë¦¬",
                    "ë‚™ì°°ê°€(ë§Œì›)",
                    "entry_cd",
                ]

                with open(
                    local_file_name, "w", encoding="utf-8-sig", newline=""
                ) as csvfile:
                    writer = csv.DictWriter(
                        csvfile, fieldnames=fieldnames, extrasaction="ignore"
                    )
                    writer.writeheader()
                    writer.writerows(all_car_data)

                print(f"âœ”ï¸ ë¡œì»¬ íŒŒì¼ '{local_file_name}'ì— ì„±ê³µì ìœ¼ë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")

                s3_bucket = "whatlunch-s3"
                s3_key = f"raw/autoinside/{yesterday_str_for_compare}/autoinside-{yesterday_str_for_filename}-raw.csv"

                print(f" S3 ë²„í‚· '{s3_bucket}'ì— ì—…ë¡œë“œë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
                s3_client = boto3.client("s3")
                s3_client.upload_file(local_file_name, s3_bucket, s3_key)
                print(f"âœ”ï¸ S3ì— ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œí–ˆìŠµë‹ˆë‹¤: s3://{s3_bucket}/{s3_key}")

            except Exception as e:
                print(f"âŒ íŒŒì¼ ì €ì¥ ë˜ëŠ” S3 ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

            finally:
                if local_file_name and os.path.exists(local_file_name):
                    os.remove(local_file_name)
                    print(f"âœ”ï¸ ë¡œì»¬ ì„ì‹œ íŒŒì¼ '{local_file_name}'ì„ ì‚­ì œí–ˆìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    asyncio.run(main())
